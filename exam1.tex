% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={exam1},
  pdfauthor={Mathias Kold},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{exam1}
\author{Mathias Kold}
\date{2024-04-18}

\begin{document}
\maketitle

\subsection{Exam 1 - OLS and
heteroskedasticity}\label{exam-1---ols-and-heteroskedasticity}

In a multiple linear regression (MLR) there are 6 assumptions.
Assumption 1-5 are called Gauss-Markov assumptions and assumption 6 is
called the normality assumption. The first 4 assumptions exist to secure
that the model is unbiased, while assumption 5 checks for
heteroskedasticity and assumption 6 checks for normality in the model.
The assumptions are: \bold{MLR1: Linear in Parameters} The model in the
population can be written as
\[y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_k x_k + u\]
where \(\beta_0, \beta_1, \ldots, \beta_k\) are the unknown parameters
of interest and \(u\) is an unobserved random error or disturbance term.

\bold{MLR2: Random Sampling}

We have a random sample of \(n\) observations,
\(\{(x_{i1}, x_{i2}, \ldots, x_{ik}, y_i) : i = 1, 2, \ldots, n\}\),
following the population model in Assumption MLR.1.

\bold{MLR3: No Perfect Collinearity}

In the sample (and therefore in the population), none of the independent
variables is constant, and there are no exact linear relationships among
the independent variables.

\bold{MLR4: Zero Conditional Mean}

The error \(u\) has an expected value of zero given any values of the
independent variables. In other words,
\[E(u | x_1, x_2, \ldots, x_k) = 0\]

\bold{MLR5: Homoskedasticity}

The error \(u\) has the same variance given any value of the explanatory
variables. In other words,
\[\text{Var}(u | x_1, x_2, \ldots, x_k) = \sigma^2\]

\bold{MLR6: Normality}

The population error \(u\) is independent of the explanatory variables
\(x_1, x_2, \ldots, x_k\) and is normally distributed with zero mean and
variance \(\sigma^2\): \(u \sim \text{Normal}(0, \sigma^2)\).

Look at the following model for bank employees wage:
\[log(salary)=\beta_0+\beta_1educ+\beta_2log(salbegin)+\beta_3male+\beta_4 minority+u\]
where salary is yearly wage (in 1000 US dollars), educ is education
measured in number of years, salbegin is the starting salary (in 1000 US
dollars) for the person's first position in the same bank, male is a
dummy variable for gender, minority is one dummy variable indicating
whether one belongs to a minority.

\subsection{1 - Estimate the model using OLS. Comment on the output and
interpret the
results}\label{estimate-the-model-using-ols.-comment-on-the-output-and-interpret-the-results}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{options}\NormalTok{(}\AttributeTok{scipen =} \DecValTok{999}\NormalTok{)}
\FunctionTok{library}\NormalTok{(readr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: pakke 'readr' blev bygget under R version 4.2.3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(foreign)}
\FunctionTok{library}\NormalTok{(car)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: pakke 'car' blev bygget under R version 4.2.3
\end{verbatim}

\begin{verbatim}
## Indlæser krævet pakke: carData
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sandwich)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: pakke 'sandwich' blev bygget under R version 4.2.3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(lmtest)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: pakke 'lmtest' blev bygget under R version 4.2.3
\end{verbatim}

\begin{verbatim}
## Indlæser krævet pakke: zoo
\end{verbatim}

\begin{verbatim}
## Warning: pakke 'zoo' blev bygget under R version 4.2.3
\end{verbatim}

\begin{verbatim}
## 
## Vedhæfter pakke: 'zoo'
\end{verbatim}

\begin{verbatim}
## De følgende objekter er maskerede fra 'package:base':
## 
##     as.Date, as.Date.numeric
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(texreg)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: pakke 'texreg' blev bygget under R version 4.2.3
\end{verbatim}

\begin{verbatim}
## Version:  1.39.3
## Date:     2023-11-09
## Author:   Philip Leifeld (University of Essex)
## 
## Consider submitting praise using the praise or praise_interactive functions.
## Please cite the JSS article in your publications -- see citation("texreg").
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data1 }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data1.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 474 Columns: 10
\end{verbatim}

\begin{verbatim}
## -- Column specification --------------------------------------------------------
## Delimiter: ","
## dbl (10): obs, idnumber, salary, lsalary, educ, salbegin, lsalbegin, male, m...
## 
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(}\FunctionTok{log}\NormalTok{(salary) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ educ }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(salbegin) }\SpecialCharTok{+}\NormalTok{ male }\SpecialCharTok{+}\NormalTok{ minority, }\AttributeTok{data =}\NormalTok{ data1)}
\FunctionTok{summary}\NormalTok{(model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = log(salary) ~ educ + log(salbegin) + male + minority, 
##     data = data1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.45572 -0.11508 -0.00516  0.10765  0.87060 
## 
## Coefficients:
##               Estimate Std. Error t value             Pr(>|t|)    
## (Intercept)    0.84868    0.07512  11.298 < 0.0000000000000002 ***
## educ           0.02327    0.00387   6.013        0.00000000366 ***
## log(salbegin)  0.82180    0.03603  22.808 < 0.0000000000000002 ***
## male           0.04816    0.01991   2.419               0.0160 *  
## minority      -0.04237    0.02034  -2.083               0.0378 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.1766 on 469 degrees of freedom
## Multiple R-squared:  0.8041, Adjusted R-squared:  0.8024 
## F-statistic: 481.3 on 4 and 469 DF,  p-value: < 0.00000000000000022
\end{verbatim}

From the estimated model it can be seen that the education variable has
a value of 0.02327 which means that one extra year of education will
raise the salary by approximately 2.3\%. The male variable has a value
0.04816 which means that being a man will raise your salary by
approximately 4.8\%. The minority variable has a value of -0.04237 which
means that minorities approximately will have a 4.2\% lower salary than
people who are not minorities. The salbegin variable have a different
interpretation because it is in log form. It has a value of 0.82180
which means that an increase of 1\% in your starting salary will make
your salary approximately 0.82\% higher.

The intercept is 0.84868 which is the value of the dependent variable,
in this case salary, when all other variables have a value of 0. So in
this case 0.84868 is the expected value of the salary for a person with
zero education, without a starting salary and someone who is not a male
or a minority.

It can also be seen that all the variables are statistically significant
at a 5\% significance level due to p-values \textless{} 0.05 but only
education and log(salbegin) are statistically significant at a 1\%
significance level.

\subsection{2 - Perform graphical model
checking.}\label{perform-graphical-model-checking.}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(model)}
\end{Highlighting}
\end{Shaded}

\includegraphics{exam1_files/figure-latex/unnamed-chunk-2-1.pdf}
\includegraphics{exam1_files/figure-latex/unnamed-chunk-2-2.pdf}
\includegraphics{exam1_files/figure-latex/unnamed-chunk-2-3.pdf}
\includegraphics{exam1_files/figure-latex/unnamed-chunk-2-4.pdf} The
residual vs fitted model shows if the residuals have non-linear
patterns. If they are equally spread around a horizontal line without
any patterns it indicates that the residuals does not have non-linear
patterns. From the plot it can be seen that the spread is quite equal
around the horizontal red line, although a few outliers exists, which
indicates a linear pattern.

The Q-Q residuals plot shows if the residuals are normally distributed.
If the residuals fit the dotted line they are normally distributed. In
this case, the residuals fit the dotted line except in the last
quantiles where they deviate a bit from the dotted line. This could
indicate that the residuals are approximately normally distributed
although not perfectly normally distributed.

The scale-location plot shows if homoskedasticity exists within the
residuals. If the residuals are spread equally around the predictors,
the model fulfills the assumption of homoskedasticity. In this case, it
can be argued that there is an increasing pattern in the spread of the
residuals which indicates heteroskedasticity.

The residuals vs leverage plot helps detect outliers in the model. It is
important because outliers can have a major impact in the model. The
residuals can be seen if they have a large Cook's distance, which is the
dashed line. In this case, it seems like there might be an outlier with
observation 218 but other than that, most of the observations does not
have a large Cook's distance.

\subsection{3 - Test for heteroskedasticity using the Breusch-Pagan test
and the special edition of the White
test.}\label{test-for-heteroskedasticity-using-the-breusch-pagan-test-and-the-special-edition-of-the-white-test.}

First, the test for heteroskedasticity can be carried out by using the
Breusch-Pagan test:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{r}\OtherTok{=}\FunctionTok{residuals}\NormalTok{(model)}
\NormalTok{res }\OtherTok{=}\NormalTok{ r}\SpecialCharTok{\^{}}\DecValTok{2}
\FunctionTok{summary}\NormalTok{(}\FunctionTok{lm}\NormalTok{(res}\SpecialCharTok{\textasciitilde{}}\NormalTok{educ }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(salbegin) }\SpecialCharTok{+}\NormalTok{ male }\SpecialCharTok{+}\NormalTok{ minority, }\AttributeTok{data =}\NormalTok{ data1))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = res ~ educ + log(salbegin) + male + minority, data = data1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.04773 -0.02506 -0.01345  0.00908  0.71750 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(>|t|)
## (Intercept)    0.0036404  0.0235992   0.154    0.877
## educ           0.0019699  0.0012157   1.620    0.106
## log(salbegin) -0.0008061  0.0113201  -0.071    0.943
## male           0.0094827  0.0062553   1.516    0.130
## minority      -0.0104497  0.0063908  -1.635    0.103
## 
## Residual standard error: 0.05548 on 469 degrees of freedom
## Multiple R-squared:  0.02923,    Adjusted R-squared:  0.02095 
## F-statistic: 3.531 on 4 and 469 DF,  p-value: 0.007475
\end{verbatim}

Because the p-value is 0.007475 which is lower than 0.05, we reject the
null hypothesis meaning that there is heteroskedasticity in the model.

We can now calculate the LM test, where we have 474 observations and
\(R^2=0.1231\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{LM }\OtherTok{=} \FloatTok{0.1231}\SpecialCharTok{*}\DecValTok{474}
\NormalTok{LM}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 58.3494
\end{verbatim}

We can then calculate the p-value of chi-square \(\chi^2_k\):

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\SpecialCharTok{{-}}\FunctionTok{pchisq}\NormalTok{(LM,}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.000000000006445178
\end{verbatim}

Both the LM and F test reject the null hypothesis meaning there is
heteroskedasticity in the model. The Breusch-Pagan test can also be
directly run in R using the bptest function which also gives us the
p-value.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(lmtest)}
\FunctionTok{bptest}\NormalTok{(model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  studentized Breusch-Pagan test
## 
## data:  model
## BP = 13.857, df = 4, p-value = 0.007767
\end{verbatim}

The special White test can also be used to do the test the model for
heteroskedasticity.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{yhat }\OtherTok{\textless{}{-}} \FunctionTok{fitted}\NormalTok{(model)}
\NormalTok{quadu }\OtherTok{\textless{}{-}}\NormalTok{ (}\FunctionTok{residuals}\NormalTok{(model)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{model\_white }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(quadu }\SpecialCharTok{\textasciitilde{}}\NormalTok{ yhat }\SpecialCharTok{+} \FunctionTok{I}\NormalTok{(yhat}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}

\NormalTok{whitetest }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"yhat=0"}\NormalTok{, }\StringTok{"I(yhat\^{}2)=0"}\NormalTok{)}
\FunctionTok{linearHypothesis}\NormalTok{(model\_white,whitetest)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Linear hypothesis test
## 
## Hypothesis:
## yhat = 0
## I(yhat^2) = 0
## 
## Model 1: restricted model
## Model 2: quadu ~ yhat + I(yhat^2)
## 
##   Res.Df    RSS Df Sum of Sq      F   Pr(>F)   
## 1    473 1.4873                                
## 2    471 1.4531  2  0.034139 5.5327 0.004217 **
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

From both the BP test and the special White test it can be seen that the
p-value is \textless{} 0.05 which means that there is heteroskedasticity
in the model.

\subsection{4 - Calculate robust standard errors for the model and
compare with the results in question
1.}\label{calculate-robust-standard-errors-for-the-model-and-compare-with-the-results-in-question-1.}

Since there is heteroskedasticity in the model, it is necessary to take
this into account, when performing a linear regression. A valid
estimator of multiple linear regression in the presence of
heteroskedasticity is
\[Var(\hat{\beta_j})=\frac{\sum\limits_{i=0}^n\hat{r}^2_{ij}\cdot\hat{u}^2_i}{(SSR_j)^2}\]
where \(\hat{r}_{ij}\) denotes the \(i\)th residual from regressing
\(x_j\) on all other independent variables. The robust standard error is
obtained by taking the square root of the above equation. R can
calculate the robust standard errors using coeftest():

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{coef\_model }\OtherTok{\textless{}{-}} \FunctionTok{coeftest}\NormalTok{(model, }\AttributeTok{vcov=}\FunctionTok{vcovHC}\NormalTok{(model,}\AttributeTok{type=}\StringTok{"HC0"}\NormalTok{))}
\FunctionTok{screenreg}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{OLS=}\NormalTok{model,}\AttributeTok{Standard\_Robust\_Error=}\NormalTok{coef\_model), }\AttributeTok{digits=}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## ==================================================
##                OLS           Standard_Robust_Error
## --------------------------------------------------
## (Intercept)      0.8487 ***   0.8487 ***          
##                 (0.0751)     (0.0794)             
## educ             0.0233 ***   0.0233 ***          
##                 (0.0039)     (0.0035)             
## log(salbegin)    0.8218 ***   0.8218 ***          
##                 (0.0360)     (0.0374)             
## male             0.0482 *     0.0482 *            
##                 (0.0199)     (0.0200)             
## minority        -0.0424 *    -0.0424 *            
##                 (0.0203)     (0.0177)             
## --------------------------------------------------
## R^2              0.8041                           
## Adj. R^2         0.8024                           
## Num. obs.      474                                
## ==================================================
## *** p < 0.001; ** p < 0.01; * p < 0.05
\end{verbatim}

It can be seen that the estimates from the two models are the same,
which is expected, because we try to account for the non-constant
variance of the error term in the OLS-model. Hence, it is only the
standard errors that change. Furthermore, the significance level does
not change, when performing a, when adjusting for heteroskedasticity.
The robust standard errors can be used to perform hypothesis testing and
to calculate confidence intervals. Even when adjusting for
heteroskedasticity, the conclusion from the regressions does not change,
since the estimates are the same, and there are no significant changes.

\subsection{\texorpdfstring{5 - Test the hypothesis \(H_0:\beta_2 = 1\)
against the alternative
\(H_1: \beta_2 \neq 1\).}{5 - Test the hypothesis H\_0:\textbackslash beta\_2 = 1 against the alternative H\_1: \textbackslash beta\_2 \textbackslash neq 1.}}\label{test-the-hypothesis-h_0beta_2-1-against-the-alternative-h_1-beta_2-neq-1.}

\(\beta_2\) is the estimate for the starting salary's effect on the the
yearly salary, so when we want to test the null hypothesis
\(H_0:\beta_2 = 1\) it means that the starting salary has an effect on
the yearly salary. (MAYBE COMMENT ON WHAT KIND OF EFFECT!).

To test our null hypothesis against the alternative hypothesis we use
the t-statistics, which is given by:
\[t_{{\hat\beta}_j}=\frac{\hat{\beta_j}-1}{se(\hat{\beta_j})}\] We will
perform a two-sided test, so the decision rule will be
\(|t_{{\hat\beta}_j}|>c\), meaning that the null hypothesis will be
rejected if the absolute value of t-statistics is greater than the
critical value.

To perform the test we use our estimate \(\hat{\beta_2}\) from 1.1.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bhat2 }\OtherTok{\textless{}{-}} \FloatTok{0.82180}
\NormalTok{se\_bhat2 }\OtherTok{\textless{}{-}} \FloatTok{0.03603}

\NormalTok{t\_stat }\OtherTok{\textless{}{-}}\NormalTok{ (bhat2 }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ se\_bhat2}
\NormalTok{t\_stat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -4.945878
\end{verbatim}

Then we need to calculate the critical values for the two-sided test:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{alpha }\OtherTok{\textless{}{-}} \FloatTok{0.05}
\NormalTok{c }\OtherTok{\textless{}{-}} \FunctionTok{qt}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{alpha}\SpecialCharTok{/}\DecValTok{2}\NormalTok{, }\DecValTok{469}\NormalTok{)}
\NormalTok{c}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.965035
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{abs}\NormalTok{(t\_stat)}\SpecialCharTok{\textgreater{}}\NormalTok{c}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

We can see that the absolute value of the t-statistic is greater than
the critical value at a 5\% significance level, meaning that we reject
the null hypothesis, so we instead accept the alternative hypothesis
saying that the starting salary does have a statistically significant
effect on the yearly salary.

Another way to test the null hypothesis is by calculating the p-value.
The definition of the p-value is the probability of obtaining a
t-statistic more or at least as extreme than the one observed in the
sample. We use R to calculate the p-value in the following way:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pval }\OtherTok{\textless{}{-}} \DecValTok{2}\SpecialCharTok{*}\FunctionTok{pt}\NormalTok{(}\SpecialCharTok{{-}}\FunctionTok{abs}\NormalTok{(t\_stat), }\DecValTok{469}\NormalTok{)}
\NormalTok{pval}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.000001057867
\end{verbatim}

So at a 5\% significance level the p-value also tells us to reject the
null hypothesis, further confirming the rejecting from the t-statistics
before.

\subsection{\texorpdfstring{6 - Test the hypothesis
\(H_0: \beta_3 = \beta_4 = 0\)}{6 - Test the hypothesis H\_0: \textbackslash beta\_3 = \textbackslash beta\_4 = 0}}\label{test-the-hypothesis-h_0-beta_3-beta_4-0}

When we want to test multiple hypothesis we turn to the F-statistics,
where we uses this formula:
\[F=\frac{R^2_{ur}-R^2_{r}}{1-R^2_{ur}}*\frac{n-k-1}{q}\] where
\(R^2_{ur}\) is the R-squared from our unrestricted model, \(R^2_{r}\)
is the R-squared from the restricted, \(q\) is the difference in the
degrees of freedom between the unrestricted and restricted model, \(n\)
is the number of observations in the dataset and \(k\) is the number of
independent variables in the unrestricted model.

In our case the unrestricted model is the one given in the beginning of
assignment 1.1 with all the independent variables, and in the case where
we want to test the null hypothesis \(H_0: \beta_3 = \beta_4 = 0\), we
then get our restricted model:
\[log(salary)=\beta_0+\beta_1educ+\beta_2log(salbegin)+u\]

So we start by estimating our restricted model:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_r }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(}\FunctionTok{log}\NormalTok{(salary) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ educ }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(salbegin), }\AttributeTok{data =}\NormalTok{ data1)}
\end{Highlighting}
\end{Shaded}

We then obtain our \(R^2\) from the restricted and unrestriced model:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{r2\_ur }\OtherTok{\textless{}{-}} \FunctionTok{summary}\NormalTok{(model)}\SpecialCharTok{$}\NormalTok{r.squared}
\NormalTok{r2\_r }\OtherTok{\textless{}{-}} \FunctionTok{summary}\NormalTok{(model\_r)}\SpecialCharTok{$}\NormalTok{r.squared}
\end{Highlighting}
\end{Shaded}

We now have what we need to calculate our F-statistic:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{F }\OtherTok{\textless{}{-}}\NormalTok{ (r2\_ur}\SpecialCharTok{{-}}\NormalTok{r2\_r)}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{r2\_ur) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{474{-}4{-}1}\NormalTok{)}\SpecialCharTok{/}\DecValTok{2}
\NormalTok{F}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4.234946
\end{verbatim}

We then calculate our critical values of the F-statistics at 5\%
significance level:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qf}\NormalTok{(}\FloatTok{0.95}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{469}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.014949
\end{verbatim}

Our decision rule says that if F \textgreater{} c then we reject our
null hypothesis and instead accepting our alternative hypothesis meaning
that \(\beta_3\) and \(\beta_4\) does have a statistically impact on
yearly salary.

It is also possible to do the test directly in R by using the following
code:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{myh0 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"male=0"}\NormalTok{, }\StringTok{"minority=0"}\NormalTok{)}
\FunctionTok{linearHypothesis}\NormalTok{(model, myh0)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Linear hypothesis test
## 
## Hypothesis:
## male = 0
## minority = 0
## 
## Model 1: restricted model
## Model 2: log(salary) ~ educ + log(salbegin) + male + minority
## 
##   Res.Df    RSS Df Sum of Sq      F  Pr(>F)  
## 1    471 14.892                              
## 2    469 14.627  2   0.26416 4.2349 0.01504 *
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

Using the code in R to perform the F-statistics gives us the some answer
as before still confirming the rejecting of our null hypothesis.

\subsection{7 - Estimate the model using FGLS and comment on the
results.}\label{estimate-the-model-using-fgls-and-comment-on-the-results.}

Feasible generalised least squares (FGLS) is a method used to adress
heteroskedasticity. It can difficult to know the form of
heteroskedasticity (i.e, h(\(x_i\))). In many cases, it is possible to
model the function \(h\) and use this data to estimate the unknown
parameters. By estimating \(h_i\), an estimated value of \(h\) is
obtained, \(\hat{h_i}\). One method to find the exact form of \(h_i\) is
as follows:
\[Var(u|x)=\sigma^2exp(\delta_0+\delta_1x_1+\delta_2x_2+...+\delta_kx_k)\]
where \(x_1,x_2,...,x_k\) are the independent variables in the
regression.

Since the parameters \(\delta\) is unknown for the population, these are
estimated using the given data, where \(\hat{h}\) can be used to account
for heteroskedasticity. To find the estimates for \(\delta\), we can use
the following. By taking log, the model can be linearised.

\[u^2=\sigma^2exp(\delta_0+\delta_1x_1+\delta_2x_2+...+\delta_kx_k)v\]

\[log(u^2)=a_0+\delta_1x_1+\delta_2x_2+...+\delta_kx_k+e\]

We already know from 1.3 that our model has heteroskedasticity problems,
so we obtain our squared residuals from our OLS model and log them:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{logu2 }\OtherTok{\textless{}{-}} \FunctionTok{log}\NormalTok{(}\FunctionTok{resid}\NormalTok{(model)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

So now we run the regression on the form mentioned earlier:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{varreg }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(logu2 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ educ }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(salbegin) }\SpecialCharTok{+}\NormalTok{ male }\SpecialCharTok{+}\NormalTok{ minority, }\AttributeTok{data =}\NormalTok{ data1)}
\end{Highlighting}
\end{Shaded}

After we calculate the weights by exponentiating the fitted values from
varreg:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{w }\OtherTok{\textless{}{-}} \FunctionTok{exp}\NormalTok{(}\FunctionTok{fitted}\NormalTok{(varreg))}
\end{Highlighting}
\end{Shaded}

And then we can estimate the FGLS:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{FGLS }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(}\FunctionTok{log}\NormalTok{(salary) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ educ }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(salbegin) }\SpecialCharTok{+}\NormalTok{ male }\SpecialCharTok{+}\NormalTok{ minority, }\AttributeTok{weight=}\DecValTok{1}\SpecialCharTok{/}\NormalTok{w, }\AttributeTok{data =}\NormalTok{ data1)}
\FunctionTok{screenreg}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{OLS=}\NormalTok{model, }\AttributeTok{FLGS=}\NormalTok{FGLS), }\AttributeTok{digits=}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## =========================================
##                OLS           FLGS        
## -----------------------------------------
## (Intercept)      0.8487 ***    0.8493 ***
##                 (0.0751)      (0.0756)   
## educ             0.0233 ***    0.0222 ***
##                 (0.0039)      (0.0038)   
## log(salbegin)    0.8218 ***    0.8270 ***
##                 (0.0360)      (0.0358)   
## male             0.0482 *      0.0487 *  
##                 (0.0199)      (0.0196)   
## minority        -0.0424 *     -0.0429 *  
##                 (0.0203)      (0.0187)   
## -----------------------------------------
## R^2              0.8041        0.8046    
## Adj. R^2         0.8024        0.8029    
## Num. obs.      474           474         
## =========================================
## *** p < 0.001; ** p < 0.01; * p < 0.05
\end{verbatim}

It can be seen that the standard error for the different variables have
been changed a bit, but nothing significant. It is very small changes,
which maybe could indicate that the FGLS estimation have not taken into
account all the heteroskedasticity. This will be elaborated further in
1.8.

\subsection{8 - Has the FGLS estimation taken into account all the
heteroskedasticity?}\label{has-the-fgls-estimation-taken-into-account-all-the-heteroskedasticity}

There are more ways to check whether the FGLS estimation has taken all
the heteroskedasticity into account. One way is to look at it
graphically and another is by doing a BP-test.

We start by looking at it graphically in the Scale-Location plot:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(FGLS, }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{exam1_files/figure-latex/unnamed-chunk-22-1.pdf}

Then we perform a BP-test:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{bptest}\NormalTok{(FGLS)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  studentized Breusch-Pagan test
## 
## data:  FGLS
## BP = 60112, df = 4, p-value < 0.00000000000000022
\end{verbatim}

Both the plot and BP-test indicates that the FGLS estimation have not
taken all of the heteroskedasticity into account. In the plot it looks
like there is a slight upward trend and that the spread of the residuals
increase with higher fitted values. This suggest that the variance of
the residuals is not constant indicating heteroskedasticity. As
mentioned in 1.3 the null hypothesis in a BP-test is homoskedasticity,
but we reject the null hypothesis here, since p-value is \textgreater{}
0.05.

\end{document}
